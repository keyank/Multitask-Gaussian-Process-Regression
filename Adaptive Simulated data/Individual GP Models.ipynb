{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "\n",
    "np.random.seed(1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = pickle.load(open(\"adaptive_data2.pickle\", 'rb'))\n",
    "X = loaded_data[\"X\"]\n",
    "Y = loaded_data[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([X, Y.reshape((151, 1))], axis=1)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "train  = data[:50, :]\n",
    "validation = data[50:100, :]\n",
    "test = data[100:150, :]\n",
    "\n",
    "\n",
    "X_train = train[:, 0:2]\n",
    "Y_train = train[:, 2]\n",
    "\n",
    "X_valid = validation[:, 0:2]\n",
    "Y_valid = validation[:, 2]\n",
    "\n",
    "\n",
    "X_test  = test[:, 0:2]\n",
    "Y_test  = test[:, 2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1 = {\n",
    "    \"X_train\" : X_train,\n",
    "    \"Y_train\" : Y_train,\n",
    "    \"X_valid\" : X_valid,\n",
    "    \"Y_valid\" : Y_valid,\n",
    "    \"X_test\"  : X_test,\n",
    "    \"Y_test\"  : Y_test\n",
    "}\n",
    "\n",
    "pickle.dump(Data1, open(\"Data/Data1.pickle\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma_u = math.pow(10, -1.5)*np.identity(2)\n",
    "C_term  = 1\n",
    "Noise_variance = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process fit and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kernel(x1, x2):  # K_input part of ICM kernel\n",
    "    numerator    = 2*np.dot(np.dot(x1, Sigma_u), x2 )\n",
    "    denominator1 = 1 + 2*np.dot(np.dot(x1, Sigma_u), x1 )\n",
    "    denominator2 = 1 + 2*np.dot(np.dot(x2, Sigma_u), x2 )\n",
    "    denominator  = math.sqrt(denominator1*denominator2) # See \"Computing with infinite networks\" for calculation of Expectation term \n",
    "    \n",
    "    Expectation_term = (2/np.pi) * math.asin( numerator/denominator )\n",
    "    similarity       = C_term +  Expectation_term  # See \"Multitask Neural networks meet Multitask Gaussian Process\" Paper for notation of C-term and Expectation term\n",
    "    return similarity \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mtgp_fit (X_train, Y_train, Noise_variance ): \n",
    "    N = len(X_train)\n",
    "    K = np.zeros((N, N))\n",
    "            \n",
    "    for i in range(0, N):\n",
    "        for j in range(0, N):\n",
    "            K[i, j] = Kernel(X_train[i],  X_train[j] )\n",
    "            \n",
    "    B = np.zeros((N, N))\n",
    "    for i in range(0, N):\n",
    "        B[i, i] = Noise_variance\n",
    "         \n",
    "    \n",
    "    C = K + B\n",
    "    C_inv = np.linalg.inv(C)\n",
    "    alpha = np.dot(C_inv, Y_train)\n",
    "    model = {\n",
    "        \"X_train\" :  X_train,\n",
    "        \"Y_train\" :  Y_train,\n",
    "        \"Noise_variance\" : Noise_variance,\n",
    "        \"C_inv\"   :  C_inv,\n",
    "        \"alpha\"   :  alpha,\n",
    "    }\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def mtgp_predict(X,  model):\n",
    "    \n",
    "    n_train  = len(model[\"X_train\"])\n",
    "    n        = len(X)\n",
    "    K        = np.zeros((n_train, n))\n",
    "    \n",
    "    for i in range(0, n_train):\n",
    "        for j in range(0, n):\n",
    "            K[i, j] = Kernel( model[\"X_train\"][i],  X[j] )\n",
    "            \n",
    "    y_pred = np.dot(K.T, model[\"alpha\"] )\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_stats (y_true, y_predict):\n",
    "    msr = mean_squared_error(y_true, y_predict)\n",
    "    stats ={\n",
    "        \"msr\" : msr\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss with True Hyperparameters : 0.0012524983745783797\n"
     ]
    }
   ],
   "source": [
    "model = mtgp_fit (X_train, Y_train, Noise_variance )\n",
    "predict = mtgp_predict(X_valid,  model)\n",
    "stats = get_stats(Y_valid, predict)\n",
    "print(\"Validation Loss with True Hyperparameters :\", stats['msr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Negative_Loss (\n",
    "    Sigma_u_temp, noise_variance_temp\n",
    "):\n",
    "    global Sigma_u\n",
    "    global Noise_variance\n",
    "    \n",
    "    Sigma_u = math.pow(10, Sigma_u_temp)*np.identity(2)\n",
    "    Noise_variance = math.pow(10, noise_variance_temp)\n",
    "    \n",
    "    model = mtgp_fit (X_train, Y_train, Noise_variance )\n",
    "    predict = mtgp_predict(X_valid,  model)\n",
    "    stats = get_stats(Y_valid, predict)\n",
    "    return -stats['msr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "pbounds = {\n",
    "            \"Sigma_u_temp\" : (-4, 2),\n",
    "            \"noise_variance_temp\" : (-6, 0),\n",
    "          }\n",
    "\n",
    "\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f= get_Negative_Loss,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | Sigma_... | noise_... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.001366\u001b[0m | \u001b[0m-1.498   \u001b[0m | \u001b[0m-1.678   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.02753 \u001b[0m | \u001b[0m-3.999   \u001b[0m | \u001b[0m-4.186   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.006324\u001b[0m | \u001b[0m-3.119   \u001b[0m | \u001b[0m-5.446   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.004972\u001b[0m | \u001b[0m-2.882   \u001b[0m | \u001b[0m-3.927   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.001274\u001b[0m | \u001b[95m-1.619   \u001b[0m | \u001b[95m-2.767   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.001285\u001b[0m | \u001b[0m-1.485   \u001b[0m | \u001b[0m-1.889   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.02218 \u001b[0m | \u001b[0m-2.773   \u001b[0m | \u001b[0m-0.7313  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.02674 \u001b[0m | \u001b[0m-3.836   \u001b[0m | \u001b[0m-1.977   \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-0.001224\u001b[0m | \u001b[95m-1.496   \u001b[0m | \u001b[95m-2.648   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.005824\u001b[0m | \u001b[0m-3.158   \u001b[0m | \u001b[0m-4.811   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.001818\u001b[0m | \u001b[0m 0.8045  \u001b[0m | \u001b[0m-0.1904  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.003105\u001b[0m | \u001b[0m-2.119   \u001b[0m | \u001b[0m-1.846   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.00133 \u001b[0m | \u001b[0m 1.258   \u001b[0m | \u001b[0m-0.6324  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.006341\u001b[0m | \u001b[0m-3.49    \u001b[0m | \u001b[0m-5.766   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.02353 \u001b[0m | \u001b[0m-2.981   \u001b[0m | \u001b[0m-0.7311  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.02214 \u001b[0m | \u001b[0m-3.41    \u001b[0m | \u001b[0m-3.473   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.001657\u001b[0m | \u001b[0m 1.747   \u001b[0m | \u001b[0m-2.801   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.001295\u001b[0m | \u001b[0m 0.1513  \u001b[0m | \u001b[0m-4.107   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.001355\u001b[0m | \u001b[0m 0.119   \u001b[0m | \u001b[0m-0.9922  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.02593 \u001b[0m | \u001b[0m-3.89    \u001b[0m | \u001b[0m-1.499   \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m-0.001209\u001b[0m | \u001b[95m 1.933   \u001b[0m | \u001b[95m-1.511   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.01182 \u001b[0m | \u001b[0m-2.317   \u001b[0m | \u001b[0m-1.264   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.0228  \u001b[0m | \u001b[0m-3.381   \u001b[0m | \u001b[0m-3.313   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.003201\u001b[0m | \u001b[0m 1.452   \u001b[0m | \u001b[0m-4.238   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.001501\u001b[0m | \u001b[0m-2.273   \u001b[0m | \u001b[0m-5.22    \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.02656 \u001b[0m | \u001b[0m-3.884   \u001b[0m | \u001b[0m-1.927   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.004784\u001b[0m | \u001b[0m-2.73    \u001b[0m | \u001b[0m-4.407   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.001313\u001b[0m | \u001b[0m-1.051   \u001b[0m | \u001b[0m-5.68    \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.001295\u001b[0m | \u001b[0m-0.5553  \u001b[0m | \u001b[0m-5.12    \u001b[0m |\n",
      "| \u001b[95m 30      \u001b[0m | \u001b[95m-0.001164\u001b[0m | \u001b[95m-0.4642  \u001b[0m | \u001b[95m-1.801   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.02091 \u001b[0m | \u001b[0m-3.386   \u001b[0m | \u001b[0m-3.516   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-0.001286\u001b[0m | \u001b[0m 0.1664  \u001b[0m | \u001b[0m-3.515   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.0275  \u001b[0m | \u001b[0m-3.7     \u001b[0m | \u001b[0m-2.785   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.001267\u001b[0m | \u001b[0m-0.01723 \u001b[0m | \u001b[0m-2.911   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.001481\u001b[0m | \u001b[0m 1.668   \u001b[0m | \u001b[0m-2.481   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-0.005834\u001b[0m | \u001b[0m 1.42    \u001b[0m | \u001b[0m-5.175   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.02477 \u001b[0m | \u001b[0m-3.164   \u001b[0m | \u001b[0m-1.156   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-0.001317\u001b[0m | \u001b[0m-1.614   \u001b[0m | \u001b[0m-5.008   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.002599\u001b[0m | \u001b[0m 1.565   \u001b[0m | \u001b[0m-3.913   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-0.001173\u001b[0m | \u001b[0m 0.5049  \u001b[0m | \u001b[0m-1.644   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.001306\u001b[0m | \u001b[0m 1.3     \u001b[0m | \u001b[0m-2.258   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-0.001387\u001b[0m | \u001b[0m 0.5057  \u001b[0m | \u001b[0m-3.907   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-0.01746 \u001b[0m | \u001b[0m-2.38    \u001b[0m | \u001b[0m-0.6247  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-0.005311\u001b[0m | \u001b[0m-1.431   \u001b[0m | \u001b[0m-0.211   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-0.001214\u001b[0m | \u001b[0m-0.01935 \u001b[0m | \u001b[0m-2.27    \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.03779 \u001b[0m | \u001b[0m-3.312   \u001b[0m | \u001b[0m-0.3031  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-0.001192\u001b[0m | \u001b[0m-1.301   \u001b[0m | \u001b[0m-2.53    \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.00132 \u001b[0m | \u001b[0m-1.551   \u001b[0m | \u001b[0m-4.578   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.00143 \u001b[0m | \u001b[0m 1.42    \u001b[0m | \u001b[0m-2.558   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.02722 \u001b[0m | \u001b[0m-3.983   \u001b[0m | \u001b[0m-2.297   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.002115\u001b[0m | \u001b[0m-2.04    \u001b[0m | \u001b[0m-2.838   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.002237\u001b[0m | \u001b[0m 1.316   \u001b[0m | \u001b[0m-3.856   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.001342\u001b[0m | \u001b[0m 1.451   \u001b[0m | \u001b[0m-2.26    \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.07513 \u001b[0m | \u001b[0m-3.905   \u001b[0m | \u001b[0m-0.4234  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.002244\u001b[0m | \u001b[0m 0.1454  \u001b[0m | \u001b[0m-0.01606 \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-0.005706\u001b[0m | \u001b[0m-2.966   \u001b[0m | \u001b[0m-5.177   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-0.001251\u001b[0m | \u001b[0m 1.596   \u001b[0m | \u001b[0m-1.819   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-0.02579 \u001b[0m | \u001b[0m-3.604   \u001b[0m | \u001b[0m-1.467   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-0.001626\u001b[0m | \u001b[0m 0.5233  \u001b[0m | \u001b[0m-0.4619  \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-0.001889\u001b[0m | \u001b[0m 0.2691  \u001b[0m | \u001b[0m-5.254   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-0.008194\u001b[0m | \u001b[0m-3.881   \u001b[0m | \u001b[0m-5.843   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m-0.02416 \u001b[0m | \u001b[0m-3.83    \u001b[0m | \u001b[0m-4.523   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m-0.0014  \u001b[0m | \u001b[0m 1.16    \u001b[0m | \u001b[0m-2.767   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-0.001569\u001b[0m | \u001b[0m-0.6831  \u001b[0m | \u001b[0m-0.9478  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-0.005868\u001b[0m | \u001b[0m-3.255   \u001b[0m | \u001b[0m-4.325   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-0.00231 \u001b[0m | \u001b[0m-0.4854  \u001b[0m | \u001b[0m-0.1824  \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m-0.001288\u001b[0m | \u001b[0m-0.6338  \u001b[0m | \u001b[0m-5.888   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m-0.002344\u001b[0m | \u001b[0m 0.8038  \u001b[0m | \u001b[0m-4.602   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-0.001578\u001b[0m | \u001b[0m 0.8426  \u001b[0m | \u001b[0m-3.673   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m-0.001175\u001b[0m | \u001b[0m 1.181   \u001b[0m | \u001b[0m-1.517   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m-0.001296\u001b[0m | \u001b[0m-0.6626  \u001b[0m | \u001b[0m-5.181   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m-0.006958\u001b[0m | \u001b[0m-3.64    \u001b[0m | \u001b[0m-5.272   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-0.008745\u001b[0m | \u001b[0m-3.733   \u001b[0m | \u001b[0m-5.355   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-0.01652 \u001b[0m | \u001b[0m-2.646   \u001b[0m | \u001b[0m-1.722   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-0.001287\u001b[0m | \u001b[0m-0.6417  \u001b[0m | \u001b[0m-5.925   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m-0.06462 \u001b[0m | \u001b[0m-3.568   \u001b[0m | \u001b[0m-0.1963  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-0.001299\u001b[0m | \u001b[0m-0.5914  \u001b[0m | \u001b[0m-4.78    \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-0.01363 \u001b[0m | \u001b[0m-2.486   \u001b[0m | \u001b[0m-1.537   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m-0.0126  \u001b[0m | \u001b[0m-2.827   \u001b[0m | \u001b[0m-2.512   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-0.001183\u001b[0m | \u001b[0m 1.82    \u001b[0m | \u001b[0m-0.919   \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m-0.003914\u001b[0m | \u001b[0m-2.561   \u001b[0m | \u001b[0m-3.037   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m-0.001442\u001b[0m | \u001b[0m-0.2803  \u001b[0m | \u001b[0m-1.026   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m-0.005483\u001b[0m | \u001b[0m-3.059   \u001b[0m | \u001b[0m-5.889   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m-0.0268  \u001b[0m | \u001b[0m-3.58    \u001b[0m | \u001b[0m-3.082   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m-0.00124 \u001b[0m | \u001b[0m-0.362   \u001b[0m | \u001b[0m-2.587   \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m-0.01432 \u001b[0m | \u001b[0m-2.096   \u001b[0m | \u001b[0m-0.0683  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m-0.001298\u001b[0m | \u001b[0m-0.5215  \u001b[0m | \u001b[0m-3.719   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m-0.001206\u001b[0m | \u001b[0m-0.6943  \u001b[0m | \u001b[0m-1.528   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m-0.001293\u001b[0m | \u001b[0m 0.0154  \u001b[0m | \u001b[0m-4.41    \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m-0.02447 \u001b[0m | \u001b[0m-3.602   \u001b[0m | \u001b[0m-3.779   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m-0.00129 \u001b[0m | \u001b[0m-0.2217  \u001b[0m | \u001b[0m-4.739   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m-0.003333\u001b[0m | \u001b[0m 0.5165  \u001b[0m | \u001b[0m-5.601   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m-0.01592 \u001b[0m | \u001b[0m-2.438   \u001b[0m | \u001b[0m-1.171   \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m-0.01784 \u001b[0m | \u001b[0m-2.839   \u001b[0m | \u001b[0m-2.163   \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m-0.002251\u001b[0m | \u001b[0m-0.852   \u001b[0m | \u001b[0m-0.4512  \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m-0.001606\u001b[0m | \u001b[0m-2.42    \u001b[0m | \u001b[0m-5.604   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m-0.00118 \u001b[0m | \u001b[0m 0.4104  \u001b[0m | \u001b[0m-1.367   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m-0.001474\u001b[0m | \u001b[0m 1.447   \u001b[0m | \u001b[0m-0.4082  \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m-0.02545 \u001b[0m | \u001b[0m-3.916   \u001b[0m | \u001b[0m-4.594   \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m-0.002083\u001b[0m | \u001b[0m-0.2993  \u001b[0m | \u001b[0m-0.3059  \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m-0.001571\u001b[0m | \u001b[0m 1.701   \u001b[0m | \u001b[0m-2.66    \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m-0.00132 \u001b[0m | \u001b[0m 1.494   \u001b[0m | \u001b[0m-2.151   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 103     \u001b[0m | \u001b[0m-0.001281\u001b[0m | \u001b[0m-1.66    \u001b[0m | \u001b[0m-3.084   \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m-0.001251\u001b[0m | \u001b[0m-0.3741  \u001b[0m | \u001b[0m-2.703   \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m-0.001398\u001b[0m | \u001b[0m 1.557   \u001b[0m | \u001b[0m-0.4876  \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m-0.007202\u001b[0m | \u001b[0m-1.631   \u001b[0m | \u001b[0m-0.2204  \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m-0.005572\u001b[0m | \u001b[0m-2.956   \u001b[0m | \u001b[0m-5.242   \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m-0.02048 \u001b[0m | \u001b[0m-3.19    \u001b[0m | \u001b[0m-2.966   \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m-0.08294 \u001b[0m | \u001b[0m-3.871   \u001b[0m | \u001b[0m-0.3122  \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m-0.01903 \u001b[0m | \u001b[0m 0.9627  \u001b[0m | \u001b[0m-5.91    \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m-0.005039\u001b[0m | \u001b[0m-2.943   \u001b[0m | \u001b[0m-4.008   \u001b[0m |\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m-0.02487 \u001b[0m | \u001b[0m-3.214   \u001b[0m | \u001b[0m-1.143   \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m-0.01071 \u001b[0m | \u001b[0m-1.932   \u001b[0m | \u001b[0m-0.3594  \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m-0.001741\u001b[0m | \u001b[0m-0.5079  \u001b[0m | \u001b[0m-0.727   \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m-0.0014  \u001b[0m | \u001b[0m 1.068   \u001b[0m | \u001b[0m-0.5676  \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m-0.001225\u001b[0m | \u001b[0m-1.241   \u001b[0m | \u001b[0m-2.722   \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m-0.001937\u001b[0m | \u001b[0m 0.7916  \u001b[0m | \u001b[0m-4.286   \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m-0.001184\u001b[0m | \u001b[0m-1.058   \u001b[0m | \u001b[0m-2.405   \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m-0.02748 \u001b[0m | \u001b[0m-3.907   \u001b[0m | \u001b[0m-2.439   \u001b[0m |\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m-0.001725\u001b[0m | \u001b[0m-1.398   \u001b[0m | \u001b[0m-1.156   \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m-0.01231 \u001b[0m | \u001b[0m-2.109   \u001b[0m | \u001b[0m-0.6427  \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m-0.001297\u001b[0m | \u001b[0m-0.5329  \u001b[0m | \u001b[0m-4.896   \u001b[0m |\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m-0.001244\u001b[0m | \u001b[0m 0.7276  \u001b[0m | \u001b[0m-2.328   \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m-0.02674 \u001b[0m | \u001b[0m-3.677   \u001b[0m | \u001b[0m-3.479   \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m-0.001774\u001b[0m | \u001b[0m 0.07441 \u001b[0m | \u001b[0m-0.4884  \u001b[0m |\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m-0.1123  \u001b[0m | \u001b[0m-3.998   \u001b[0m | \u001b[0m-0.1394  \u001b[0m |\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m-0.008817\u001b[0m | \u001b[0m-1.741   \u001b[0m | \u001b[0m-0.1573  \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m-0.001462\u001b[0m | \u001b[0m-0.3717  \u001b[0m | \u001b[0m-1.027   \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m-0.00119 \u001b[0m | \u001b[0m-0.5517  \u001b[0m | \u001b[0m-2.232   \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m-0.00303 \u001b[0m | \u001b[0m-2.287   \u001b[0m | \u001b[0m-2.479   \u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m-0.001338\u001b[0m | \u001b[0m 0.5001  \u001b[0m | \u001b[0m-0.8501  \u001b[0m |\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m-0.001186\u001b[0m | \u001b[0m 0.5305  \u001b[0m | \u001b[0m-1.812   \u001b[0m |\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m-0.002352\u001b[0m | \u001b[0m 1.187   \u001b[0m | \u001b[0m-4.064   \u001b[0m |\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m-0.001283\u001b[0m | \u001b[0m 0.02473 \u001b[0m | \u001b[0m-3.295   \u001b[0m |\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m-0.001298\u001b[0m | \u001b[0m-1.707   \u001b[0m | \u001b[0m-3.535   \u001b[0m |\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m-0.001316\u001b[0m | \u001b[0m-1.591   \u001b[0m | \u001b[0m-4.096   \u001b[0m |\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m-0.001287\u001b[0m | \u001b[0m-0.2685  \u001b[0m | \u001b[0m-3.419   \u001b[0m |\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m-0.001316\u001b[0m | \u001b[0m 1.843   \u001b[0m | \u001b[0m-1.933   \u001b[0m |\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m-0.0046  \u001b[0m | \u001b[0m-2.809   \u001b[0m | \u001b[0m-3.44    \u001b[0m |\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m-0.004576\u001b[0m | \u001b[0m-1.94    \u001b[0m | \u001b[0m-1.214   \u001b[0m |\n",
      "| \u001b[0m 141     \u001b[0m | \u001b[0m-0.001363\u001b[0m | \u001b[0m 1.28    \u001b[0m | \u001b[0m-0.5769  \u001b[0m |\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m-0.001291\u001b[0m | \u001b[0m-0.02368 \u001b[0m | \u001b[0m-4.379   \u001b[0m |\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m-0.01857 \u001b[0m | \u001b[0m-2.486   \u001b[0m | \u001b[0m-0.8706  \u001b[0m |\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m-0.001388\u001b[0m | \u001b[0m-0.8337  \u001b[0m | \u001b[0m-1.187   \u001b[0m |\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m-0.001186\u001b[0m | \u001b[0m-0.5651  \u001b[0m | \u001b[0m-1.601   \u001b[0m |\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m-0.001273\u001b[0m | \u001b[0m-0.8859  \u001b[0m | \u001b[0m-1.375   \u001b[0m |\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m-0.001289\u001b[0m | \u001b[0m-0.5869  \u001b[0m | \u001b[0m-3.206   \u001b[0m |\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m-0.001322\u001b[0m | \u001b[0m-1.944   \u001b[0m | \u001b[0m-5.591   \u001b[0m |\n",
      "| \u001b[0m 149     \u001b[0m | \u001b[0m-0.001313\u001b[0m | \u001b[0m-1.732   \u001b[0m | \u001b[0m-5.522   \u001b[0m |\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m-0.00274 \u001b[0m | \u001b[0m 1.897   \u001b[0m | \u001b[0m-4.91    \u001b[0m |\n",
      "| \u001b[0m 151     \u001b[0m | \u001b[0m-0.001317\u001b[0m | \u001b[0m 0.8712  \u001b[0m | \u001b[0m-0.7502  \u001b[0m |\n",
      "| \u001b[0m 152     \u001b[0m | \u001b[0m-0.001247\u001b[0m | \u001b[0m 0.1305  \u001b[0m | \u001b[0m-2.583   \u001b[0m |\n",
      "| \u001b[0m 153     \u001b[0m | \u001b[0m-0.01074 \u001b[0m | \u001b[0m-3.034   \u001b[0m | \u001b[0m-3.199   \u001b[0m |\n",
      "| \u001b[0m 154     \u001b[0m | \u001b[0m-0.001342\u001b[0m | \u001b[0m-1.929   \u001b[0m | \u001b[0m-4.65    \u001b[0m |\n",
      "| \u001b[0m 155     \u001b[0m | \u001b[0m-0.001298\u001b[0m | \u001b[0m-0.4449  \u001b[0m | \u001b[0m-4.126   \u001b[0m |\n",
      "| \u001b[0m 156     \u001b[0m | \u001b[0m-0.001364\u001b[0m | \u001b[0m 1.498   \u001b[0m | \u001b[0m-0.5422  \u001b[0m |\n",
      "| \u001b[0m 157     \u001b[0m | \u001b[0m-0.001636\u001b[0m | \u001b[0m-2.457   \u001b[0m | \u001b[0m-5.335   \u001b[0m |\n",
      "| \u001b[0m 158     \u001b[0m | \u001b[0m-0.006804\u001b[0m | \u001b[0m-2.842   \u001b[0m | \u001b[0m-3.002   \u001b[0m |\n",
      "| \u001b[0m 159     \u001b[0m | \u001b[0m-0.00167 \u001b[0m | \u001b[0m 0.3715  \u001b[0m | \u001b[0m-4.751   \u001b[0m |\n",
      "| \u001b[0m 160     \u001b[0m | \u001b[0m-0.01896 \u001b[0m | \u001b[0m-2.512   \u001b[0m | \u001b[0m-0.89    \u001b[0m |\n",
      "| \u001b[0m 161     \u001b[0m | \u001b[0m-0.001234\u001b[0m | \u001b[0m-1.505   \u001b[0m | \u001b[0m-2.3     \u001b[0m |\n",
      "| \u001b[0m 162     \u001b[0m | \u001b[0m-0.001883\u001b[0m | \u001b[0m-2.598   \u001b[0m | \u001b[0m-5.388   \u001b[0m |\n",
      "| \u001b[0m 163     \u001b[0m | \u001b[0m-0.001288\u001b[0m | \u001b[0m-0.9049  \u001b[0m | \u001b[0m-3.137   \u001b[0m |\n",
      "| \u001b[0m 164     \u001b[0m | \u001b[0m-0.0234  \u001b[0m | \u001b[0m-3.084   \u001b[0m | \u001b[0m-2.269   \u001b[0m |\n",
      "| \u001b[95m 165     \u001b[0m | \u001b[95m-0.001158\u001b[0m | \u001b[95m-0.7359  \u001b[0m | \u001b[95m-2.075   \u001b[0m |\n",
      "| \u001b[0m 166     \u001b[0m | \u001b[0m-0.02518 \u001b[0m | \u001b[0m-3.133   \u001b[0m | \u001b[0m-1.491   \u001b[0m |\n",
      "| \u001b[0m 167     \u001b[0m | \u001b[0m-0.004634\u001b[0m | \u001b[0m-2.668   \u001b[0m | \u001b[0m-2.884   \u001b[0m |\n",
      "| \u001b[0m 168     \u001b[0m | \u001b[0m-0.01131 \u001b[0m | \u001b[0m 0.7118  \u001b[0m | \u001b[0m-5.866   \u001b[0m |\n",
      "| \u001b[0m 169     \u001b[0m | \u001b[0m-0.01037 \u001b[0m | \u001b[0m-2.054   \u001b[0m | \u001b[0m-0.7625  \u001b[0m |\n",
      "| \u001b[0m 170     \u001b[0m | \u001b[0m-0.001364\u001b[0m | \u001b[0m 1.068   \u001b[0m | \u001b[0m-2.769   \u001b[0m |\n",
      "| \u001b[0m 171     \u001b[0m | \u001b[0m-0.001609\u001b[0m | \u001b[0m 1.2     \u001b[0m | \u001b[0m-0.3012  \u001b[0m |\n",
      "| \u001b[0m 172     \u001b[0m | \u001b[0m-0.001245\u001b[0m | \u001b[0m 0.9584  \u001b[0m | \u001b[0m-0.8753  \u001b[0m |\n",
      "| \u001b[0m 173     \u001b[0m | \u001b[0m-0.02662 \u001b[0m | \u001b[0m-3.408   \u001b[0m | \u001b[0m-2.092   \u001b[0m |\n",
      "| \u001b[0m 174     \u001b[0m | \u001b[0m-0.001228\u001b[0m | \u001b[0m 0.2211  \u001b[0m | \u001b[0m-2.339   \u001b[0m |\n",
      "| \u001b[0m 175     \u001b[0m | \u001b[0m-0.013   \u001b[0m | \u001b[0m 0.7977  \u001b[0m | \u001b[0m-5.793   \u001b[0m |\n",
      "| \u001b[0m 176     \u001b[0m | \u001b[0m-0.001172\u001b[0m | \u001b[0m 0.6214  \u001b[0m | \u001b[0m-1.61    \u001b[0m |\n",
      "| \u001b[0m 177     \u001b[0m | \u001b[0m-0.002235\u001b[0m | \u001b[0m-2.442   \u001b[0m | \u001b[0m-4.458   \u001b[0m |\n",
      "| \u001b[0m 178     \u001b[0m | \u001b[0m-0.001294\u001b[0m | \u001b[0m-0.2062  \u001b[0m | \u001b[0m-3.928   \u001b[0m |\n",
      "| \u001b[0m 179     \u001b[0m | \u001b[0m-0.001385\u001b[0m | \u001b[0m 0.7795  \u001b[0m | \u001b[0m-3.323   \u001b[0m |\n",
      "| \u001b[0m 180     \u001b[0m | \u001b[0m-0.002013\u001b[0m | \u001b[0m 0.6965  \u001b[0m | \u001b[0m-0.05717 \u001b[0m |\n",
      "| \u001b[0m 181     \u001b[0m | \u001b[0m-0.001449\u001b[0m | \u001b[0m-2.199   \u001b[0m | \u001b[0m-5.142   \u001b[0m |\n",
      "| \u001b[0m 182     \u001b[0m | \u001b[0m-0.001501\u001b[0m | \u001b[0m 1.408   \u001b[0m | \u001b[0m-2.751   \u001b[0m |\n",
      "| \u001b[0m 183     \u001b[0m | \u001b[0m-0.001405\u001b[0m | \u001b[0m 1.848   \u001b[0m | \u001b[0m-2.18    \u001b[0m |\n",
      "| \u001b[0m 184     \u001b[0m | \u001b[0m-0.001679\u001b[0m | \u001b[0m 1.963   \u001b[0m | \u001b[0m-2.724   \u001b[0m |\n",
      "| \u001b[0m 185     \u001b[0m | \u001b[0m-0.001305\u001b[0m | \u001b[0m-0.8414  \u001b[0m | \u001b[0m-5.187   \u001b[0m |\n",
      "| \u001b[0m 186     \u001b[0m | \u001b[0m-0.001313\u001b[0m | \u001b[0m-1.866   \u001b[0m | \u001b[0m-5.843   \u001b[0m |\n",
      "| \u001b[0m 187     \u001b[0m | \u001b[0m-0.02462 \u001b[0m | \u001b[0m-3.038   \u001b[0m | \u001b[0m-1.526   \u001b[0m |\n",
      "| \u001b[0m 188     \u001b[0m | \u001b[0m-0.02711 \u001b[0m | \u001b[0m-3.818   \u001b[0m | \u001b[0m-3.801   \u001b[0m |\n",
      "| \u001b[0m 189     \u001b[0m | \u001b[0m-0.001215\u001b[0m | \u001b[0m 1.174   \u001b[0m | \u001b[0m-1.844   \u001b[0m |\n",
      "| \u001b[0m 190     \u001b[0m | \u001b[0m-0.001384\u001b[0m | \u001b[0m 0.1457  \u001b[0m | \u001b[0m-4.868   \u001b[0m |\n",
      "| \u001b[0m 191     \u001b[0m | \u001b[0m-0.001191\u001b[0m | \u001b[0m-1.349   \u001b[0m | \u001b[0m-2.511   \u001b[0m |\n",
      "| \u001b[0m 192     \u001b[0m | \u001b[0m-0.002633\u001b[0m | \u001b[0m 1.939   \u001b[0m | \u001b[0m-4.777   \u001b[0m |\n",
      "| \u001b[0m 193     \u001b[0m | \u001b[0m-0.002832\u001b[0m | \u001b[0m-2.514   \u001b[0m | \u001b[0m-4.427   \u001b[0m |\n",
      "| \u001b[0m 194     \u001b[0m | \u001b[0m-0.001289\u001b[0m | \u001b[0m 0.501   \u001b[0m | \u001b[0m-3.258   \u001b[0m |\n",
      "| \u001b[0m 195     \u001b[0m | \u001b[0m-0.02734 \u001b[0m | \u001b[0m-3.658   \u001b[0m | \u001b[0m-2.949   \u001b[0m |\n",
      "| \u001b[0m 196     \u001b[0m | \u001b[0m-0.02158 \u001b[0m | \u001b[0m-2.728   \u001b[0m | \u001b[0m-1.208   \u001b[0m |\n",
      "| \u001b[0m 197     \u001b[0m | \u001b[0m-0.00139 \u001b[0m | \u001b[0m-2.216   \u001b[0m | \u001b[0m-5.834   \u001b[0m |\n",
      "| \u001b[0m 198     \u001b[0m | \u001b[0m-0.001547\u001b[0m | \u001b[0m-0.4394  \u001b[0m | \u001b[0m-0.937   \u001b[0m |\n",
      "| \u001b[0m 199     \u001b[0m | \u001b[0m-0.001897\u001b[0m | \u001b[0m-1.714   \u001b[0m | \u001b[0m-1.501   \u001b[0m |\n",
      "| \u001b[0m 200     \u001b[0m | \u001b[0m-0.001248\u001b[0m | \u001b[0m-0.9332  \u001b[0m | \u001b[0m-2.754   \u001b[0m |\n",
      "| \u001b[0m 201     \u001b[0m | \u001b[0m-0.001876\u001b[0m | \u001b[0m 1.994   \u001b[0m | \u001b[0m-0.01416 \u001b[0m |\n",
      "| \u001b[0m 202     \u001b[0m | \u001b[0m-0.002275\u001b[0m | \u001b[0m 1.998   \u001b[0m | \u001b[0m-3.679   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 203     \u001b[0m | \u001b[0m-0.001334\u001b[0m | \u001b[0m 1.999   \u001b[0m | \u001b[0m-0.5416  \u001b[0m |\n",
      "| \u001b[0m 204     \u001b[0m | \u001b[0m-0.002193\u001b[0m | \u001b[0m-2.23    \u001b[0m | \u001b[0m-3.642   \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(\n",
    "    init_points=200,\n",
    "    n_iter=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma_u = math.pow(10, -1.5)*np.identity(2)\n",
    "C_term  = 1\n",
    "Noise_variance = 1e-3\n",
    "\n",
    "\n",
    "\n",
    "model = mtgp_fit (X_train, Y_train, Noise_variance )\n",
    "predict = mtgp_predict(X_test,  model)\n",
    "stats = get_stats(Y_test, predict)\n",
    "print(\"Test Loss with True Hyperparameters : \", stats['msr'])\n",
    "\n",
    "\n",
    "\n",
    "Sigma_u = math.pow(10, optimizer.max['params'][\"Sigma_u_temp\"] )*np.identity(2)\n",
    "C_term  = 1\n",
    "Noise_variance = math.pow(10, optimizer.max['params'][\"noise_variance_temp\"]  )\n",
    "\n",
    "\n",
    "model = mtgp_fit (X_train, Y_train, Noise_variance )\n",
    "predict = mtgp_predict(X_test,  model)\n",
    "stats = get_stats(Y_test, predict)\n",
    "print(\"Test Loss with BO Hyperparameters : \", stats['msr'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
