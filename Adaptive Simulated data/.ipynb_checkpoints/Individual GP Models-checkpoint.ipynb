{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "\n",
    "np.random.seed(1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = pickle.load(open(\"adaptive_data2.pickle\", 'rb'))\n",
    "X = loaded_data[\"X\"]\n",
    "Y = loaded_data[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([X, Y.reshape((151, 1))], axis=1)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "train  = data[:50, :]\n",
    "validation = data[50:100, :]\n",
    "test = data[100:150, :]\n",
    "\n",
    "\n",
    "X_train = train[:, 0:2]\n",
    "Y_train = train[:, 2]\n",
    "\n",
    "X_valid = validation[:, 0:2]\n",
    "Y_valid = validation[:, 2]\n",
    "\n",
    "\n",
    "X_test  = test[:, 0:2]\n",
    "Y_test  = test[:, 2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1 = {\n",
    "    \"X_train\" : X_train,\n",
    "    \"Y_train\" : Y_train,\n",
    "    \"X_valid\" : X_valid,\n",
    "    \"Y_valid\" : Y_valid,\n",
    "    \"X_test\"  : X_test,\n",
    "    \"Y_test\"  : Y_test\n",
    "}\n",
    "\n",
    "pickle.dump(Data1, open(\"Data/Data1.pickle\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma_u = math.pow(10, -1.5)*np.identity(2)\n",
    "C_term  = 1\n",
    "Noise_variance = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process fit and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kernel(x1, x2):  # K_input part of ICM kernel\n",
    "    numerator    = 2*np.dot(np.dot(x1, Sigma_u), x2 )\n",
    "    denominator1 = 1 + 2*np.dot(np.dot(x1, Sigma_u), x1 )\n",
    "    denominator2 = 1 + 2*np.dot(np.dot(x2, Sigma_u), x2 )\n",
    "    denominator  = math.sqrt(denominator1*denominator2) # See \"Computing with infinite networks\" for calculation of Expectation term \n",
    "    \n",
    "    Expectation_term = (2/np.pi) * math.asin( numerator/denominator )\n",
    "    similarity       = C_term +  Expectation_term  # See \"Multitask Neural networks meet Multitask Gaussian Process\" Paper for notation of C-term and Expectation term\n",
    "    return similarity \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mtgp_fit (X_train, Y_train, Noise_variance ): \n",
    "    N = len(X_train)\n",
    "    K = np.zeros((N, N))\n",
    "            \n",
    "    for i in range(0, N):\n",
    "        for j in range(0, N):\n",
    "            K[i, j] = Kernel(X_train[i],  X_train[j] )\n",
    "            \n",
    "    B = np.zeros((N, N))\n",
    "    for i in range(0, N):\n",
    "        B[i, i] = Noise_variance\n",
    "         \n",
    "    \n",
    "    C = K + B\n",
    "    C_inv = np.linalg.inv(C)\n",
    "    alpha = np.dot(C_inv, Y_train)\n",
    "    model = {\n",
    "        \"X_train\" :  X_train,\n",
    "        \"Y_train\" :  Y_train,\n",
    "        \"Noise_variance\" : Noise_variance,\n",
    "        \"C_inv\"   :  C_inv,\n",
    "        \"alpha\"   :  alpha,\n",
    "    }\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def mtgp_predict(X,  model):\n",
    "    \n",
    "    n_train  = len(model[\"X_train\"])\n",
    "    n        = len(X)\n",
    "    K        = np.zeros((n_train, n))\n",
    "    \n",
    "    for i in range(0, n_train):\n",
    "        for j in range(0, n):\n",
    "            K[i, j] = Kernel( model[\"X_train\"][i],  X[j] )\n",
    "            \n",
    "    y_pred = np.dot(K.T, model[\"alpha\"] )\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_stats (y_true, y_predict):\n",
    "    msr = mean_squared_error(y_true, y_predict)\n",
    "    stats ={\n",
    "        \"msr\" : msr\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012524983745783797\n"
     ]
    }
   ],
   "source": [
    "model = mtgp_fit (X_train, Y_train, Noise_variance )\n",
    "predict = mtgp_predict(X_valid,  model)\n",
    "stats = get_stats(Y_valid, predict)\n",
    "print(stats['msr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Negative_Loss (\n",
    "    Sigma_u_temp, noise_variance_temp\n",
    "):\n",
    "    global Sigma_u\n",
    "    global Noise_variance\n",
    "    \n",
    "    Sigma_u = math.pow(10, Sigma_u_temp)*np.identity(2)\n",
    "    Noise_variance = math.pow(10, noise_variance_temp)\n",
    "    \n",
    "    model = mtgp_fit (X_train, Y_train, Noise_variance )\n",
    "    predict = mtgp_predict(X_valid,  model)\n",
    "    stats = get_stats(Y_valid, predict)\n",
    "    return -stats['msr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "pbounds = {\n",
    "            \"Sigma_u_temp\" : (-4, 2),\n",
    "            \"noise_variance_temp\" : (-6, 0),\n",
    "          }\n",
    "\n",
    "\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f= get_Negative_Loss,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | Sigma_... | noise_... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.001209\u001b[0m | \u001b[0m 1.933   \u001b[0m | \u001b[0m-1.511   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.01182 \u001b[0m | \u001b[0m-2.317   \u001b[0m | \u001b[0m-1.264   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.0228  \u001b[0m | \u001b[0m-3.381   \u001b[0m | \u001b[0m-3.313   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.003201\u001b[0m | \u001b[0m 1.452   \u001b[0m | \u001b[0m-4.238   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.001501\u001b[0m | \u001b[0m-2.273   \u001b[0m | \u001b[0m-5.22    \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-0.02656 \u001b[0m | \u001b[0m-3.884   \u001b[0m | \u001b[0m-1.927   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-0.004784\u001b[0m | \u001b[0m-2.73    \u001b[0m | \u001b[0m-4.407   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-0.001313\u001b[0m | \u001b[0m-1.051   \u001b[0m | \u001b[0m-5.68    \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-0.001295\u001b[0m | \u001b[0m-0.5553  \u001b[0m | \u001b[0m-5.12    \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-0.001164\u001b[0m | \u001b[0m-0.4642  \u001b[0m | \u001b[0m-1.801   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-0.02091 \u001b[0m | \u001b[0m-3.386   \u001b[0m | \u001b[0m-3.516   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m-0.001286\u001b[0m | \u001b[0m 0.1664  \u001b[0m | \u001b[0m-3.515   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m-0.0275  \u001b[0m | \u001b[0m-3.7     \u001b[0m | \u001b[0m-2.785   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-0.001267\u001b[0m | \u001b[0m-0.01723 \u001b[0m | \u001b[0m-2.911   \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-0.001481\u001b[0m | \u001b[0m 1.668   \u001b[0m | \u001b[0m-2.481   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-0.005834\u001b[0m | \u001b[0m 1.42    \u001b[0m | \u001b[0m-5.175   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m-0.02477 \u001b[0m | \u001b[0m-3.164   \u001b[0m | \u001b[0m-1.156   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m-0.001317\u001b[0m | \u001b[0m-1.614   \u001b[0m | \u001b[0m-5.008   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-0.002599\u001b[0m | \u001b[0m 1.565   \u001b[0m | \u001b[0m-3.913   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m-0.001173\u001b[0m | \u001b[0m 0.5049  \u001b[0m | \u001b[0m-1.644   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m-0.001306\u001b[0m | \u001b[0m 1.3     \u001b[0m | \u001b[0m-2.258   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m-0.001387\u001b[0m | \u001b[0m 0.5057  \u001b[0m | \u001b[0m-3.907   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-0.01746 \u001b[0m | \u001b[0m-2.38    \u001b[0m | \u001b[0m-0.6247  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-0.005311\u001b[0m | \u001b[0m-1.431   \u001b[0m | \u001b[0m-0.211   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-0.001214\u001b[0m | \u001b[0m-0.01935 \u001b[0m | \u001b[0m-2.27    \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m-0.03779 \u001b[0m | \u001b[0m-3.312   \u001b[0m | \u001b[0m-0.3031  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-0.001192\u001b[0m | \u001b[0m-1.301   \u001b[0m | \u001b[0m-2.53    \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-0.00132 \u001b[0m | \u001b[0m-1.551   \u001b[0m | \u001b[0m-4.578   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m-0.00143 \u001b[0m | \u001b[0m 1.42    \u001b[0m | \u001b[0m-2.558   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-0.02722 \u001b[0m | \u001b[0m-3.983   \u001b[0m | \u001b[0m-2.297   \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m-0.002115\u001b[0m | \u001b[0m-2.04    \u001b[0m | \u001b[0m-2.838   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m-0.002237\u001b[0m | \u001b[0m 1.316   \u001b[0m | \u001b[0m-3.856   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m-0.001342\u001b[0m | \u001b[0m 1.451   \u001b[0m | \u001b[0m-2.26    \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m-0.07513 \u001b[0m | \u001b[0m-3.905   \u001b[0m | \u001b[0m-0.4234  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m-0.002244\u001b[0m | \u001b[0m 0.1454  \u001b[0m | \u001b[0m-0.01606 \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m-0.005706\u001b[0m | \u001b[0m-2.966   \u001b[0m | \u001b[0m-5.177   \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m-0.001251\u001b[0m | \u001b[0m 1.596   \u001b[0m | \u001b[0m-1.819   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m-0.02579 \u001b[0m | \u001b[0m-3.604   \u001b[0m | \u001b[0m-1.467   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m-0.001626\u001b[0m | \u001b[0m 0.5233  \u001b[0m | \u001b[0m-0.4619  \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m-0.001889\u001b[0m | \u001b[0m 0.2691  \u001b[0m | \u001b[0m-5.254   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m-0.008194\u001b[0m | \u001b[0m-3.881   \u001b[0m | \u001b[0m-5.843   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m-0.02416 \u001b[0m | \u001b[0m-3.83    \u001b[0m | \u001b[0m-4.523   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m-0.0014  \u001b[0m | \u001b[0m 1.16    \u001b[0m | \u001b[0m-2.767   \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m-0.001569\u001b[0m | \u001b[0m-0.6831  \u001b[0m | \u001b[0m-0.9478  \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m-0.005868\u001b[0m | \u001b[0m-3.255   \u001b[0m | \u001b[0m-4.325   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m-0.00231 \u001b[0m | \u001b[0m-0.4854  \u001b[0m | \u001b[0m-0.1824  \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m-0.001288\u001b[0m | \u001b[0m-0.6338  \u001b[0m | \u001b[0m-5.888   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m-0.002344\u001b[0m | \u001b[0m 0.8038  \u001b[0m | \u001b[0m-4.602   \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m-0.001578\u001b[0m | \u001b[0m 0.8426  \u001b[0m | \u001b[0m-3.673   \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m-0.001175\u001b[0m | \u001b[0m 1.181   \u001b[0m | \u001b[0m-1.517   \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m-0.002573\u001b[0m | \u001b[0m 1.996   \u001b[0m | \u001b[0m-5.415   \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m-0.001299\u001b[0m | \u001b[0m-1.427   \u001b[0m | \u001b[0m-3.521   \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m-0.001305\u001b[0m | \u001b[0m 0.002798\u001b[0m | \u001b[0m-4.772   \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m-0.001201\u001b[0m | \u001b[0m 0.8269  \u001b[0m | \u001b[0m-1.057   \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m-0.001292\u001b[0m | \u001b[0m-0.2734  \u001b[0m | \u001b[0m-5.455   \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m-0.001319\u001b[0m | \u001b[0m-1.215   \u001b[0m | \u001b[0m-4.07    \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m-0.001561\u001b[0m | \u001b[0m-1.747   \u001b[0m | \u001b[0m-2.238   \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m-0.001165\u001b[0m | \u001b[0m 1.57    \u001b[0m | \u001b[0m-1.077   \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m-0.001317\u001b[0m | \u001b[0m-1.871   \u001b[0m | \u001b[0m-5.566   \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m-0.001207\u001b[0m | \u001b[0m-0.9332  \u001b[0m | \u001b[0m-1.521   \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m-0.001288\u001b[0m | \u001b[0m-0.8221  \u001b[0m | \u001b[0m-3.126   \u001b[0m |\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m-0.001253\u001b[0m | \u001b[0m-0.2332  \u001b[0m | \u001b[0m-1.338   \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m-0.001241\u001b[0m | \u001b[0m 0.7188  \u001b[0m | \u001b[0m-2.297   \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m-0.00133 \u001b[0m | \u001b[0m-2.082   \u001b[0m | \u001b[0m-5.996   \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m-0.001462\u001b[0m | \u001b[0m 1.715   \u001b[0m | \u001b[0m-0.3936  \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m-0.005884\u001b[0m | \u001b[0m-3.12    \u001b[0m | \u001b[0m-5.999   \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m-0.001369\u001b[0m | \u001b[0m-1.873   \u001b[0m | \u001b[0m-3.429   \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m-0.001788\u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m-2.904   \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m-0.001296\u001b[0m | \u001b[0m-0.3519  \u001b[0m | \u001b[0m-3.963   \u001b[0m |\n",
      "| \u001b[95m 120     \u001b[0m | \u001b[95m-0.001134\u001b[0m | \u001b[95m-1.044   \u001b[0m | \u001b[95m-2.046   \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m-0.001751\u001b[0m | \u001b[0m-0.1354  \u001b[0m | \u001b[0m-0.6019  \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m-0.001387\u001b[0m | \u001b[0m 0.2195  \u001b[0m | \u001b[0m-4.659   \u001b[0m |\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m-0.001169\u001b[0m | \u001b[0m 1.998   \u001b[0m | \u001b[0m-1.002   \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m-0.001279\u001b[0m | \u001b[0m 0.5812  \u001b[0m | \u001b[0m-2.966   \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m-0.001367\u001b[0m | \u001b[0m 1.999   \u001b[0m | \u001b[0m-2.017   \u001b[0m |\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m-0.001743\u001b[0m | \u001b[0m 1.405   \u001b[0m | \u001b[0m-3.235   \u001b[0m |\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m-0.001323\u001b[0m | \u001b[0m-1.798   \u001b[0m | \u001b[0m-4.213   \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m-0.001242\u001b[0m | \u001b[0m-0.3657  \u001b[0m | \u001b[0m-2.607   \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m-0.00129 \u001b[0m | \u001b[0m-0.2056  \u001b[0m | \u001b[0m-5.077   \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m-0.001272\u001b[0m | \u001b[0m-1.384   \u001b[0m | \u001b[0m-3.161   \u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m-0.001289\u001b[0m | \u001b[0m-0.5715  \u001b[0m | \u001b[0m-5.62    \u001b[0m |\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m-0.001434\u001b[0m | \u001b[0m 1.999   \u001b[0m | \u001b[0m-0.4071  \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(\n",
    "    init_points=50,\n",
    "    n_iter=50,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
